MMU
===

Virtual addresses are on 41 bits for k1c when using 64bit mode.
To differentiate kernel from user space, we use the high order bit
(bit 40). if 1 , the higher remaining bits must also be set to one
and it is kernel space. The same applied for 0 and it's user space
mapping.

Memory Map
==========

In Linux physical memories are arranged into banks according to the cost of an
access in term of distance to a memory. As we are UMA architecture we only have
one bank and thus one node.

A node is divided into several kind of zone. For example if DMA can only access
a specific area in the physical memory we will define a ZONE_DMA for this purpose.
In our case we are considering that DMA can access all DDR so we don't have a specific
zone for this. On 64 bit architecture all DDR can be mapped in virtual kernel space
so there is no need for a ZONE_HIGHMEM. That means that in our case there is
only one ZONE_NORMAL. This will be updated if DMA cannot access all memory.

Currently, the memory mapping is the following for 4KB page:

+-----------------------+-----------------------+------+-------+--------------+
| Start                 | End                   | Attr | Size  | Name         |
+-----------------------+-----------------------+------+-------+--------------+
| 0000 0000 0000 0000   | 0000 003F FFFF FFFF   | ---  | 256GB | User         |
| 0000 0040 0000 0000   | 0000 007F FFFF FFFF   | ---  | 256GB |   MMAP       |
| 0000 0080 0000 0000   | FFFF FF7F FFFF FFFF   | ---  | ---   | Gap          |
| FFFF FF80 0000 0000   | FFFF FFFF FFFF FFFF   | ---  | 512GB | Kernel       |
|   FFFF FF80 0000 0000 |   FFFF FF80 3FFF FFFF | R-X  | 1GB   |   Text       |
|   FFFF FF80 4000 0000 |   FFFF FF80 7FFF FFFF | RWX  | 1GB   |   Vmalloc    |
|   FFFF FF80 8000 0000 |   FFFF FFFF FFFF FFFF | RW   | 510GB |   Free area  |
+-----------------------+-----------------------+------+-------+--------------+

Enable the MMU
==============

Except the k1c_start() function which loaded at 0x0 in physical memory, all other kernel
functions and symbols are in virtual memory. To be able to switch from physical
addresses to virtual addresses there is different solution. We choose to setup the
TLB at the very beginning of the boot process to be able to run both piece of code.
For this we added two entries in the LTLB. The first one, LTLB[0], contains the
mapping between virtual memory and DDR. Its size is 1Go. The second entry, LTLB[1],
contains a flat mapping of the first 512Ko of the SMEM. Once those two entries
are present we can enable the MMU. LTLB[1] will be removed during paging_init()
because once we are really running in virtual space we don't need it anymore.
This entry is then reused to map devices mmu entry. This mapping is used for
ioremap.

Privilege Level
================
Since we are using privilege levels on k1, we make use of the virtual
spaces to be in the same space as the user. The kernel will have the
$ps.mmup set in kernel (PL1) and unset for user (PL2).
As said in k1c documentation, we have two cases when the kernel is
booted:
- Either we have been booted by someone (bootloader, hypervisor, etc)
- Or we are alone (boot from flash)

In both cases, we will use the virtual space 0. Indeed, if we are alone
on the core, then it means nobody is using the MMU and we can take the
first virtual space. If not alone, then when writing an entry to the tlb
using writetlb instruction, the hypervisor will catch it and change the
virtual space accordingly.

Memblock
========

When the kernel starts there is no memory allocator available. One of the first
step in the kernel is to detect the amount of DDR available by getting this
information in the device tree and initialize the low-level "memblock" allocator.

We start by reserving memory for the whole kernel. On the ISS we can see that
512Mo of DDR are managed by the memory allocator and some physical memory is
reserved for the kernel:

setup_bootmem: Memory  : 0x100000000 - 0x120000000
setup_bootmem: Reserved: 0x10001f000 - 0x1002d1bc0

During the paging init we need to set:
  - min_low_pfn that is the lowest PFN available in the system
  - max_low_pfn that indicates the end if NORMAL zone
  - max_pfn that is the number of pages in the system

This setting is used for dividing memory into pages and for configuring the
zone. See the memory map section for more information about ZONE.

Zones are configured in free_area_init_core(). During start_kernel() other
allocations are done for command line, cpu areas, PID hash table, different
caches for VFS. This allocator is used until mem_init() is called.

mem_init() is provided by the architecture. For MPPA we just call
free_all_bootmem() that will go through all pages that are not used by the
low level allocator and mark them as not used. So physical pages that are
reserved for the kernel are still used and remain in physical memory. All pages
released will now be used by the buddy allocator.

Peripherals
===========

Currently, peripherals are fully mapped in a single 1G page. This is not
the final mapping since we would like to use a dynamic mapping for that.
Moreover, PCIe mapping will be necessary dynamic and using JTLB.
The current ioremap implementation is simply adding the peripheral virtual
address offset to the requested io address. We do not add any mapping
since we use the existing resident full peripheral mapping.

LTLB Usage
==========

LTLB is used to add resident mapping which allows for faster MMU lookup.
Currently, the LTLB is used to map some mandatory kernel pages.

Page Table
==========

We support three levels for the page table and 4KB for page size.

3 levels page table
-------------------

...-----+--------+--------+--------+--------+--------+
      40|39    32|31    24|23    16|15     8|7      0|
...-----++-------+--+-----+---+----+----+---+--------+
         |          |         |         |
         |          |         |         +--->  [11:0] Offset (12 bits)
         |          |         +------------->  [20:12] PTE offset (9 bits)
         |          +----------------------->  [29:21] PMD offset (9 bits)
         +---------------------------------->  [39:30] PGD offset (10 bits)
Bits 40 to 64 are signed extended according to bit 39. If bit 39 is equal to 1
we are in kernel space.

As 10 bits are used for PGD we need to allocate 2 pages.

4 levels page table
-------------------

The problem with the 4 levels page table is that it will require more memory
accesses. As the page table walk is fully software we want to reduce the number
of load and store to memory so we will avoid to use it. Of course it's even more
true for a 5 level page table.

Conclusion:

Today we are only supporting 4Ko page size. If we want support page of 64Ko we
will need to use a layout like this one:

...---+--------+--------+--------+--------+--------+
    40|39    32|31    24|23    16|15     8|7      0|
...--++------+-+----+---+--------++-------+--------+
     |       |      |             |
     |       |      |             +------->  [15:0] Offset (16 bits)
     |       |      +--------------------->  [27:16] PTE offset (12 bits)
     |       +---------------------------->  [33:28] PMD offset (6 bits)
     +------------------------------------>  [40:34] PGD offset (7 bits)
Bits 41 to 64 are signed extended according to bit 40. If bit 40 is equal to 1
we are dealing with kernel addresses. As we can see we are loosing memory space
so a better layout could be to use a 2 level page table. It will also reduce
the number of load and store in memory.

PTE format
==========

About the format of the PTE entry, as we are not forced by hardware for choices,
we choose to follow the format described in the RiscV implementation.

    +----...----+---------+---+---+---+---+---+---+---+---+---+
    | 63 ... 12 | 11 .. 9 | 8 | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 |
    +----...----+---------+---+---+---+---+---+---+---+---+---+
         PFN       Unused  DEV  D   A   G   U   X   W   R   P

       where:
        P: Present
        R: Read
        W: Write
        X: Executable
        U: User
        G: Global
        A: Accessed
        D: Dirty
        DEV: Device space mapping
        PFN: Page frame number (depends on page size)

Fast TLB refill
===============

K1C core does not feature a hardware page walker. This work must be done
by the core in software. In order to optimize TLB refill, a special fast
path is taken when entering in kernel space.
In order to speed up the process, the following actions are taken:
1 - save some registers in a per process scratchpad
2 - If the trap is a nomapping then try the fastpath
3 - Save some more registers for this fastpath
4 - Try to walk the page table
  4.1 - If entry is not present, take the slowpath
5 - Refill the tlb properly
6 - Exit by restoring only a few registers
